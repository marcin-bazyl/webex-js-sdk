
import LoggerProxy from '../common/logs/logger-proxy';
import ParameterError from '../common/errors/parameter';
import Media from '../media';
import MeetingUtil from '../meeting/util';

const TYPE_AUDIO = 'audio';
const TYPE_VIDEO = 'video';

/*
  Certain aspects of server interaction for video muting are not implemented as we currently don't support remote muting of video.
  If we ever need to support it, search for REMOTE_MUTE_VIDEO_MISSING_IMPLEMENTATION string to find the places that need updating
*/

const createMuteState = (type, meeting, mediaDirection) => {
  if (!mediaDirection.sendAudio) {
    return null;
  }
  console.log('marcin: creating MuteState(', type, ')');

  return new MuteState(type, meeting);
};

/* eslint class-methods-use-this: ["error", { "exceptMethods": ["isSelf"] }] */

class MuteState {
  constructor(type, meeting) {
    // todo: initial values?
    // todo: current code doesn't create the state machine when we're not sending audio at all, I think we need to change this because the new SM handles also remote mute
    if ((type !== TYPE_AUDIO) && (type !== TYPE_VIDEO)) {
      throw new ParameterError('Mute state is designed for handling audio or video only');
    }
    if (!meeting) {
      throw new ParameterError('Mute state requires a meeting instance');
    }
    this.type = type;
    this.meeting = meeting;
    this.state = {
      userDesiredState: { // todo: rename to clientState, serverState, also userMuteRequest -> handleClientMuteRequest
        localMute: false,
        remoteMute: false
      },
      currentServerState: {
        localMute: false,
        remoteMute: false
      },
      requestInProgress: false
    };
    // these 2 hold the resolve,reject methods for the promise we returned to the client in last userMuteRequest() call
    this.pendingPromiseResolve = null;
    this.pendingPromiseReject = null;
  }

  userMuteRequest(mute) {
    if (mute === this.state.userDesiredState.localMute) {
      LoggerProxy.logger.info(`Meeting:muteState#userMuteRequest --> ${this.type}: ignoring user request as it is matching existing desired state`);

      return Promise.resolve();
    }

    LoggerProxy.logger.info(`Meeting:muteState#userMuteRequest --> ${this.type}: user requesting new mute state: ${mute}`);

    this.state.userDesiredState.localMute = mute;
    if (!mute) {
      this.state.userDesiredState.remoteMute = mute;
    }
    this.applyLocalMute();

    return new Promise((resolve, reject) => {
      if (this.pendingPromiseResolve) {
        // resolve the last promise we returned to the client as the client has issued a new request that has superseded the previous one
        this.pendingPromiseResolve();
      }
      this.pendingPromiseResolve = resolve;
      this.pendingPromiseReject = reject;
      this.syncDesiredStateWithServer();
    });
  }

  applyLocalMute() {
    Media.setLocalTrack(
      !this.state.userDesiredState.localMute,
      (this.type === TYPE_AUDIO) ? this.meeting.mediaProperties.audioTrack : this.meeting.mediaProperties.videoTrack
    );
  }

  isDesiredStateMatchingServerState() {
    LoggerProxy.logger.info(`Meeting:muteState#isDesiredStateMatchingServerState --> ${this.type}: comparing local mute desired state with server: ${this.state.userDesiredState.localMute} ?= ${this.state.currentServerState.localMute}`);
    LoggerProxy.logger.info(`Meeting:muteState#isDesiredStateMatchingServerState --> ${this.type}: comparing remote mute desired state with server: ${this.state.userDesiredState.remoteMute} ?= ${this.state.currentServerState.remoteMute}`);

    const isLocalMuteMatching = (this.state.userDesiredState.localMute === this.state.currentServerState.localMute);
    const isRemoteMuteMatching = (this.state.userDesiredState.remoteMute === this.state.currentServerState.remoteMute);

    return {isLocalMuteMatching, isRemoteMuteMatching};
  }

  syncDesiredStateWithServer() {

    if (this.state.requestInProgress) {
      LoggerProxy.logger.info(`Meeting:muteState#syncDesiredStateWithServer --> ${this.type}: request in progress, we need to wait for it to complete`);
      return;
    }

    const {isLocalMuteMatching, isRemoteMuteMatching} = this.isDesiredStateMatchingServerState();

    if (isLocalMuteMatching && isRemoteMuteMatching) {
      LoggerProxy.logger.info(`Meeting:muteState#syncDesiredStateWithServer --> ${this.type}: desired state already matching server state, nothing to do`);

      this.pendingPromiseResolve();
      this.pendingPromiseResolve = null;
      this.pendingPromiseReject = null;
      return;
    }

    this.state.requestInProgress = true;

    // first sync local mute with server
    const localMuteSyncPromise = (!isLocalMuteMatching) ? this.sendLocalMuteRequestToServer() : Promise.resolve();

    localMuteSyncPromise
      .then(() =>
        // then follow it up with remote mute sync
        ((!isRemoteMuteMatching) ? this.sendRemoteMuteRequestToServer() : Promise.resolve()))
      .then(() => {
        this.state.requestInProgress = false;
        LoggerProxy.logger.info(`Meeting:muteState#syncDesiredStateWithServer --> ${this.type}: sync with server completed`);

        // need to check if a new sync is required, because userDesiredState may have changed while we were doing the current sync
        this.syncDesiredStateWithServer();
      })
      .catch((e) => {
        this.state.requestInProgress = false;

        this.pendingPromiseReject(e);
        this.pendingPromiseResolve = null;
        this.pendingPromiseReject = null;
      });
  }

  sendLocalMuteRequestToServer() {
    const meetingAudio = this.meeting.audio;
    const meetingVideo = this.meeting.video;

    let audioMuted = (meetingAudio ? meetingAudio.muted : true);
    let videoMuted = (meetingVideo ? meetingVideo.muted : true);

    if (this.type === TYPE_AUDIO) {
      audioMuted = this.state.userDesiredState.localMute;
    }
    else {
      videoMuted = this.state.userDesiredState.localMute;
    }

    LoggerProxy.logger.info(`Meeting:muteState#sendLocalMuteRequestToServer --> ${this.type}: sending local mute (audio=${audioMuted}, video=${videoMuted}) to server`);

    return MeetingUtil.remoteUpdateAudioVideo(audioMuted, videoMuted, this.meeting)
      .then((locus) => {
        LoggerProxy.logger.info(
          `Meeting:muteState#sendLocalMuteRequestToServer --> ${this.type}: local mute (audio=${audioMuted}, video=${videoMuted}) applied to server`
        );

        // todo: temp hack, really I think we should parse the locus reply and make sure that onFullLocus ends up calling handleServerLocalMuteUpdate - although not sure about 429 case
        this.state.currentServerState.localMute = (this.type === TYPE_AUDIO) ? audioMuted : videoMuted;

        this.meeting.locusInfo.onFullLocus(locus); // this will also end up calling handleServerLocalMuteUpdate() ( todo )

        return locus;
      })
      .catch((remoteUpdateError) => {
        LoggerProxy.logger.info(
          `Meeting:muteState#sendLocalMuteRequestToServer --> ${this.type}: failed to apply local mute (audio=${audioMuted}, video=${videoMuted}) to server: ${remoteUpdateError}`
        );

        return Promise.reject(remoteUpdateError);
      });
  }

  sendRemoteMuteRequestToServer() {
    if (this.type === TYPE_AUDIO) {
      const remoteMuted = this.state.userDesiredState.remoteMute;

      LoggerProxy.logger.info(`Meeting:muteState#sendRemoteMuteRequestToServer --> ${this.type}: sending remote mute:${remoteMuted} to server`);

      return this.meeting.members.muteMember(this.meeting.members.selfId, remoteMuted)
        .then(() => {
          LoggerProxy.logger.info(
            `Meeting:muteState#sendRemoteMuteRequestToServer --> ${this.type}: remote mute:${remoteMuted} applied to server`
          );

          // todo: decide if we want to keep this
          this.state.currentServerState.remoteMute = remoteMuted;
        })
        .catch((remoteUpdateError) => {
          LoggerProxy.logger.info(
            `Meeting:muteState#sendRemoteMuteRequestToServer --> ${this.type}: failed to apply remote mute ${remoteMuted} to server: ${remoteUpdateError}`
          );

          return Promise.reject(remoteUpdateError);
        });
    }

    // for now we don't need to support remote muting of video (REMOTE_MUTE_VIDEO_MISSING_IMPLEMENTATION)
    return Promise.resolve();
  }

  // handleServerLocalMuteUpdate() {
  //   // todo
  // }

  handleServerRemoteMuteUpdate(muted) {
    if (muted === this.state.currentServerState.remoteMute) {
      LoggerProxy.logger.info(`Meeting:muteState#handleServerRemoteMuteUpdate --> ${this.type}: currentServerState.remoteMute already matching server state (${muted})`);
    }

    LoggerProxy.logger.info(`Meeting:muteState#handleServerRemoteMuteUpdate --> ${this.type}: updating server remoteMute to (${muted})`);
    this.state.currentServerState.remoteMute = muted;
    // todo: notification to the user - should it be from here or the layer that calls handleServerRemoteMuteUpdate() ?
  }

  // these 2 methods are here just for backward compatibility
  isMuted() {
    return this.state.userDesiredState.localMute || this.state.userDesiredState.remoteMute ||
      this.state.currentServerState.localMute || this.state.currentServerState.remoteMute;
  }

  isSelf() {
    return true; // yes, this is silly, but that's what we've been always returning // todo (remove eslint directive if we fix this)
  }
}
// todo: handle 429


// todo
// webex-web-client Module:MeetingsComponent Method:joinMeetingAction Error:Cannot read property 'then' of undefined status code: 0, error code: 0, tracking id: none  Log:error joining meeting with destination

export default createMuteState;
